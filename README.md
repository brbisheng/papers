LSTM - RNN

CNN
  - max-/average- pooling (after convolutional layer)
  - fully connected <font style='color:red'>end of CNN</font>
  - convolutional layer (filter, stride, zero padding)
  - receptive field
  - detection (landmark detection / bounding box detection)
  - Intersection over union
  - archor boxes?
  - Non-max suppresion
  - yolo
  - R - CNN
  - one shot learning
  - Siamese network
  - style matrix
  - ResNet (residual network)
  - inception modules

- GAN
  - implict/explicit density
BERT
OPENAI GPT2
Encoder-Decoder

- Metrics
  - KL divergence.



### others
- good: https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/

### useful Lecture notes from edu

LSTM:
  - shitty 
    - http://pages.cs.wisc.edu/~shavlik/cs638/lectureNotes/Long%20Short-Term%20Memory%20Networks.pdf
  - useful
    - soso: http://slazebni.cs.illinois.edu/spring17/lec02_rnn.pdf
    - good: http://people.cs.pitt.edu/~jlee/papers/cs3750_rnn_lstm_slides.pdf; http://people.cs.pitt.edu/~jlee/index.html#tutorial
      - https://pytorch.org/tutorials/

ResNet:
  - useful:
    - https://cv-tricks.com/keras/understand-implement-resnets/
